\usepackage[table]{xcolor}
\definecolor{mygreen}{RGB}{0, 90, 0}
\newcommand\original[1]{\textcolor{red}{#1}}
\newcommand\TODO[1]{\textcolor{red}{[TODO: #1]}}

%%%%%% EDITING MACROS %%%%%%%%%

\newcommand\new[1]{\textcolor{blue}{#1}}
\newcommand\old[1]{\sout{#1}}
% orange for EI
\definecolor{orange}{rgb}{1,0.5,0}
\newcommand\ei[2]{\sout{#1} \textcolor{orange}{#2}}
\newcommand\eic[1]{\textcolor{orange}{[#1]}}
% green for JW
% \definecolor{green}{rgb}{0,0.5,0}
\newcommand\jw[2]{\sout{#1} \textcolor{purple}{#2}}
\newcommand\jwc[1]{\textcolor{purple}{[#1]}}
% purple for JJ
\definecolor{purple}{rgb}{0.5,0,1}
\newcommand\jj[2]{\sout{#1} \textcolor{purple}{#2}}
\newcommand\jjc[1]{\textcolor{purple}{[Josh: #1]}}
% cyan for AR
\definecolor{cyan}{rgb}{0,.5,.5}
\newcommand\ar[2]{\sout{#1} \textcolor{cyan}{#2}}
\newcommand\arc[1]{\textcolor{cyan}{#1}}
% light brown for KT
\definecolor{lightbrown}{rgb}{0.5,0.5,0}
\newcommand\kt[2]{\sout{#1} \textcolor{lightbrown}{#2}}
\newcommand\ktc[1]{\textcolor{lightbrown}{#1}}

%They recommend five guiding principles: stakeholder engagement, complete model documentation, complete description of data used, communicating uncerainty, and testable model outcomes. 
\newcommand\editModelingGuidanceFirst{There are many guidelines available regarding the use of mechanistic models for policy influence. For instance, Behrend et al.~\cite{behrend20} conducted an extensive literature review on modeling principles and standards. They used this review to develop general recommendations for policy-guiding modeling. This review is particularly relevant given that their recommendations are specifically intended for the modeling of neglected tropical diseases, which includes cholera. Their resulting recommendations for communicating model results align with other manifestos on the proper use of models intended to inform policy \cite{saltelli20,donnelly18}, each emphasizing the importance of involving stakeholders in the modeling process, transparency, and communicating uncertainty. Other recommendations that focus on issues of model calibration and assessment also exist \cite{dahabreh17,egger17,penaloza15}, demonstrating the considerable amount of published guidance on how to effectively model dynamic systems.}

\newcommand\editModelingGuidanceSecond{Based on our assessment and literature review, \cite{lee20} was among the studies that best followed these general recommendations for policy-driven modeling. Concretly, \cite{lee20} follows at least four of the five principles outlined in \cite{behrend20}: \emph{complete model documentation}, \emph{complete description of data used}, \emph{communicating uncertainty}, and \emph{testable model outcomes}. Determining the level of adherence to the first principle, \emph{stakeholder engagement}, is difficult based solely on the article. Despite this, the inconsistency between their forecasts and the cholera incidence from 2019 to 2022 suggests that existing recommendations and standards related to policy-driven modeling may be insufficient. \cite{saltelli19} suggests that improvements in model model-based outputs may be obtained by developing structures and standards based on statistical principles. Our general recommendations therefore complement and extend existing guidelines by focusing on the methodological tasks of calibrating and evaluating dynamic models in a rigorous statistical framework. We specifically emphasize principles that proved essential in our case study; complementary methodological suggestions arising from a spatio-temporal analysis of COVID-19 are given in \cite{li23}.}

\newcommand\editMechModels{Mechanistic models representing biological phenomena are valuable for epidemiology and consequently for public health policy \cite{lofgren14,mccabe21}. More broadly, they have useful roles throughout biology, expecially when combined with statistical methods that properly account for stochasticity and nonlinearity \cite{may04}. In some situations, modern machine learning methods, which are associative by nature, can outperform mechanistic models on epidemiological forecasting tasks \cite{lau22,baker18}. The predictive skill of non-mechansitic models can reveal limitations in mechanistic models, but cannot readily replace the scientific understanding obtained by describing the biological dynamics of the system in a mathematical model \cite{baker18}.}

\newcommand\editDiscussionOne{In our cholera case study, we highlight the importance of model diagnostics; they are instrumental in enhancing model fits, thus leading to more trustworthy conclusions. We compared the Models 1--3 of \cite{lee20} to simple statistical benchmarks, enabling us to identify deficiencies in the models that could be improved. In the case of Model~3, comparing a fitted model to a benchmark and then following up by questioning why the model did not describe the data as efficiently as its benchmark helped us discern that the model fell short in explaining the surge in cholera transmission following Hurricane Matthew. This led us to suggest a model modification. Because Model~1 outperformed its benchmark model, we were able to confidently scrutinize the implications of the fitted model. We found that the seasonality term of Model~1 closely mirrors the seasonal rainfall patterns in Haiti, reaffirming alternative evidence of the importance of rainfall as a driver of cholera infection and bolstering our confidence in Model~1's ability to capture the critical dynamics of the cholera outbreak.}

\newcommand\editDiscussionTwo{Likelihood based inference enables researchers to choose between any model that is evaluated on the same dataset using a metric like AIC. Nested model variations are particularly useful as they enable formal statistical testing of the nested features. The cholera case study demonstrated the advantage of such a model variation in all three models. For instance, we tested the inclusion of a trend in transmission rate over time in Model~1; in Model~2, we considered adding an additional phase parameter, which enables a shift in the seasonal peaks of cholera infections; in Model~3, we included additional parameters such as those associated with Hurricane Matthew. In all these cases, we found strong statistical evidence in favor of these model variations over their simpler counterparts.}

\newcommand\editDiscussionThree{Another important consideration when fitting a mechanistic model to a dynamic system is the complexity of the model. Mathematical models necessarily simplify complex dynamical systems in order to make inference possible. Decision-making about which features of a system need to be incorporated in a model and which should be excluded can significantly influence the model-based conclusions. However, these decisions can be tested using a likelihood-based framework. Standard model decisions cover deterministic versus stochastic modeling and the decision to include or exclude a meta-population structure. Model benchmarks can assist in determining the level of complexity to be used in the model, enabling researchers to gauge a model's relative performance against a better-understood statistical model.}

\newcommand\editDiscussionFour{The three models in this case study offer a unique combination of decisions of model complexity. Model~3 provides an interesting example in that it is both stochastic and has a meta-population structure, making it challenging to draw likelihood-based inferences. In this paper, we demonstrated how this model class could be calibrated to incidence data using the innovative IBPF algorithm. One of only a few examples of fitting a model with this level of complexity, this case study exemplifies the algorithm's potential benefits and provides an example for future researchers on a possible approach to fitting a high-dimensional non-linear model.}

\newcommand\editDiscussionFive{If forecasts are an important component of a modeling task, the most recent information on the dynamic system should be considered with increased importance. This is particularly true for long time series, as the latent states from simulations from initial conditions may be more likely to diverge from the truth as time increases. One way to address this issue is by simulating forward from the filtering distribution at the last available time point, as this proceedure considers available evidence about the latent states of a system under the framework of the dynamic model. This type of forecasting, however, is not possible using a deterministic model. Deterministic simulations may also result in over-confidence in model forecasts, as they can only account for uncertainty due to the parameter estimation proceedure \cite{king15}. Despite these limitations, forecasts from deterministic models can provide valuable insights on potential future trends, though researchers should be transparent about these limitations when presenting forecasts from deterministic models.}

\newcommand\editModVacc{Because Model~1 only accounts for national level disease dynamics, the pre-determined department-specific vaccination campaigns are carried out by assuming the vaccines are administered in one week to the same number of individuals that would have obtained vaccines if explicitly administered to the specific departments. We refer readers to \cite{lee20} and the accompanying supplement material for more details.}

\newcommand\editForecastOne{Forecasts of a dynamic system should ideally be based on the most recent information available as it is likely to be more relevant than older data. While this assertion may seem self-evident, it is not the case for deterministic models, for which the initial conditions together with the parameters are sufficient for forecasting, and so recent data do not have special importance. Epidemiological forecasts based on deterministic models are not uncommon in practice, despite their limitations \cite{king15}. Lee et al.~\cite{lee20} chose to obtain forecasts from all of their models by simulating forward from initial conditions.
This decision is possibly as a result of using a deterministic model: forecasts from different models may only be considered comparable only if they are obtained in the same way, which must be by simulating from initial conditions because Model~2 is deterministic.} 

\newcommand\editForecastTwo{In contrast, for non-deterministic Models~1 and 3, we obtain forecasts by simulating future values using latent states that are harmonious with the most recent data. This is done by drawing latent states at the last observation time ($t_N$) from the filtering distribution $f_{\bm{X}_N|\bm{Y}_{1:N}}(\bm{x}_{N} | \bm{y}^*_{1:N} ; \hat\paramVec)$. The decision to obtain model forecasts from initial conditions partially explains the unsuccessful forecasts of Lee et al.~\cite{lee20}. Table~S7 in their supplement material, which contains results that were not discussed in their main article, shows that the subset of their simulations which were consistent with observing zero cases from 2019-2020 were also more consistent with the disappearance of cholera from Haiti from 2019-2022. These results support our argument: forecasts of a dynamic system should start with latent states that are consistent with available data.}

\newcommand\editMetaPop{In our literature review, 17 articles considered dynamic models that incorporate spatial heterogeneity \cite{lee20,tuite11,pasetto18,fitzgibbon20,eisenberg13,rinaldo12,chao11,abrams13,trevisin22,sallah17,collins14,kelly16,azman12,leung22,kuhn14,mari15,gatto12}. All but four \cite{lee20,pasetto18,sallah17,azman12} of these studies used deterministic dynamic models, which greatly simplifies the process of calibrating model parameters to incidence data. The model in \cite{pasetto18} was fit using an Ensemble Kalman Filter (EnKF) \cite{evensen09}; though EnKF scales favorably with the number of spatial units, it relies on linearization of latent states which can be problematic for highly nonlinear systems \cite{evensen22,ionides21}. Alternative approaches used to fit stochastic models included making additional simplifying assumptions to aid in the fitting process \cite{lee20}, and using MCMC algorithms \cite{sallah17,azman12} which require specific structures in the latent dynamics, making these algorithms non plug-and-play. In this subsection, we present how the recently developed iterated block particle filter (IBPF) algorithm \cite{ning21ibpf,ionides22} can be used to fit a spatially explicit stochastic dynamic model to incidence data.}